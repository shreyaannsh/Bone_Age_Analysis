{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T23:53:43.985658Z",
     "iopub.status.busy": "2025-03-29T23:53:43.985351Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.5 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n",
      "100%|██████████| 20.5M/20.5M [00:00<00:00, 200MB/s]\n",
      "100%|██████████| 316/316 [03:51<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Train Loss: 15603.3783, Val Loss: 12967.8775\n",
      "Best model saved with Val Loss: 12967.8775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 316/316 [02:44<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/25], Train Loss: 12729.8836, Val Loss: 12268.0037\n",
      "Best model saved with Val Loss: 12268.0037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 316/316 [02:43<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/25], Train Loss: 10734.8315, Val Loss: 9118.2122\n",
      "Best model saved with Val Loss: 9118.2122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 316/316 [02:42<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/25], Train Loss: 9044.3867, Val Loss: 8209.8449\n",
      "Best model saved with Val Loss: 8209.8449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 316/316 [02:43<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/25], Train Loss: 7512.3327, Val Loss: 5970.7094\n",
      "Best model saved with Val Loss: 5970.7094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 316/316 [02:45<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/25], Train Loss: 6516.1617, Val Loss: 5908.9110\n",
      "Best model saved with Val Loss: 5908.9110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 34/316 [00:18<02:23,  1.97it/s]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class BoneAgeModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BoneAgeModel, self).__init__()\n",
    "        self.model = models.efficientnet_b0(pretrained=True)\n",
    "        self.model.classifier = nn.Linear(1280, 1)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x).squeeze(1)  \n",
    "\n",
    "# Define Albumentations Transforms\n",
    "train_transforms = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "    A.Normalize(mean=[0.5], std=[0.5]),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "valid_transforms = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    A.Normalize(mean=[0.5], std=[0.5]),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# Define Custom Dataset\n",
    "class BoneAgeDataset(Dataset):\n",
    "    def __init__(self, df, img_folder, transform=None):\n",
    "        self.df = df\n",
    "        self.img_folder = img_folder\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_folder, str(self.df.iloc[idx, 0]) + \".png\")\n",
    "        \n",
    "        # Read as grayscale and convert to RGB\n",
    "        image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if image is None:\n",
    "            raise FileNotFoundError(f\"Image not found: {img_path}\")\n",
    "\n",
    "        image = np.stack([image] * 3, axis=-1)  # Convert grayscale to 3 channels\n",
    "\n",
    "        # Apply transformations\n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=image)\n",
    "            image = transformed[\"image\"]\n",
    "\n",
    "        label = torch.tensor(self.df.iloc[idx, 1], dtype=torch.float32)  # Bone Age in months\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "#  Load Data\n",
    "df = pd.read_csv(\"/kaggle/input/boneage-dataset/BoneAge_Dataset/BoneAge_train.csv\")  # Update path\n",
    "img_folder = \"/kaggle/input/boneage-dataset/BoneAge_Dataset/Training_dataset_Boneage\"  # Update path\n",
    "\n",
    "dataset = BoneAgeDataset(df, img_folder, transform=train_transforms)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "train_dataset.transform = train_transforms\n",
    "val_dataset.transform = valid_transforms\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "# Define Training Function\n",
    "def train(model, train_loader, val_loader, device, epochs=10, lr=1e-4):\n",
    "    model.to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    best_model_path = \"best_model.pth\"\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for images, labels in tqdm(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                val_loss += criterion(outputs, labels).item()\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        scheduler.step()\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "        \n",
    "        # Save the best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(f\"Best model saved with Val Loss: {best_val_loss:.4f}\")\n",
    "\n",
    "# Run Training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BoneAgeModel()\n",
    "\n",
    "train(model, train_loader, val_loader, device, epochs=25, lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"best_model.pth\")\n",
    "print(\"✅ Best model saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "model.eval()  # Set model to evaluation mode\n",
    "print(\"✅ Model loaded for inference!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the Model Class (Must match trained model)\n",
    "class BoneAgeModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BoneAgeModel, self).__init__()\n",
    "        self.model = models.efficientnet_b0(pretrained=False)  # No need to download weights again\n",
    "        self.model.classifier = nn.Linear(1280, 1)  # Regression output\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x).squeeze(1)  # Output shape (batch,)\n",
    "\n",
    "#  Load the trained model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BoneAgeModel()\n",
    "model.load_state_dict(torch.load(\"/kaggle/working/best_model.pth\", map_location=device))\n",
    "model.to(device)\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Define Albumentations Transforms for Test Images\n",
    "test_transforms = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    A.Normalize(mean=[0.5], std=[0.5]),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# Define Custom Test Dataset\n",
    "class BoneAgeTestDataset(Dataset):\n",
    "    def __init__(self, img_folder, transform=None):\n",
    "        self.img_folder = img_folder\n",
    "        self.transform = transform\n",
    "        self.image_ids = sorted(os.listdir(img_folder))  # Get all image filenames\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.image_ids[idx]\n",
    "        img_path = os.path.join(self.img_folder, img_id)\n",
    "\n",
    "        # Read as grayscale and convert to RGB\n",
    "        image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if image is None:\n",
    "            raise FileNotFoundError(f\"Image not found: {img_path}\")\n",
    "\n",
    "        image = np.stack([image] * 3, axis=-1)  # Convert grayscale to 3 channels\n",
    "\n",
    "        # Apply transformations\n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=image)\n",
    "            image = transformed[\"image\"]\n",
    "\n",
    "        return image, img_id.replace(\".png\", \"\")  \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "\n",
    "\n",
    "test_folder = \"/kaggle/input/boneage-dataset/BoneAge_Dataset/Test_dataset_BoneAge\"  # Update path\n",
    "test_dataset = BoneAgeTestDataset(test_folder, transform=test_transforms)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, image_ids in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        outputs = outputs.cpu().numpy()  \n",
    "\n",
    "        \n",
    "        for img_id, pred in zip(image_ids, outputs):\n",
    "            predictions.append((img_id, pred))\n",
    "\n",
    "\n",
    "submission_df = submission_df[submission_df[\"ID\"] != \"BoneAge_test_1742\"]\n",
    "\n",
    "submission_df.to_csv(\"/kaggle/working/submission.csv\", index=False)\n",
    "\n",
    "print(\"✅ Submission file saved: /kaggle/working/submission.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6993120,
     "sourceId": 11207107,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
